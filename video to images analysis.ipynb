{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get images from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-69567da1dc01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mextractFrames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NiyonikaChhabra_VideoResume.mp4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-69567da1dc01>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mextractFrames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NiyonikaChhabra_VideoResume.mp4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-69567da1dc01>\u001b[0m in \u001b[0;36mextractFrames\u001b[1;34m(pathIn, pathOut)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextractFrames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathIn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathOut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathOut\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathIn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'data'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "def extractFrames(pathIn, pathOut):\n",
    "    os.mkdir(pathOut)\n",
    "    cap = cv2.VideoCapture(pathIn)\n",
    "    count = 0\n",
    "    while (cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            print('Read %d frame: ' % count, ret)\n",
    "            cv2.imwrite(os.path.join(pathOut, \"frame{:d}.jpg\".format(count)), frame)  # save frame as JPEG file\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "def main():\n",
    "    extractFrames('NiyonikaChhabra_VideoResume.mp4', 'data')\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze video, displaying the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\external_software\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "25-02-2021:23:49:57,842 INFO     [classes.py:210] 30.33 fps, 1770 frames, 58.37 seconds\n",
      "25-02-2021:23:49:57,846 INFO     [classes.py:218] Making directories at output\n",
      "25-02-2021:23:49:57,851 INFO     [classes.py:344] Deleted pre-existing output\\NiyonikaChhabra_VideoResume_output.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n",
      "Starting to Zip\n",
      "Zip has finished\n"
     ]
    }
   ],
   "source": [
    "from fer import Video\n",
    "from fer import FER\n",
    "video_filename = (r\"C:\\Users\\harsh\\Desktop\\video_analytics\\Video\\NiyonikaChhabra_VideoResume.mp4\")\n",
    "video = Video(video_filename)\n",
    "detector = FER(mtcnn=True)\n",
    "video.analyze(detector, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\external_software\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'box': (131, 183, 195, 195),\n",
       "  'emotions': {'angry': 0.0,\n",
       "   'disgust': 0.0,\n",
       "   'fear': 0.01,\n",
       "   'happy': 0.93,\n",
       "   'sad': 0.0,\n",
       "   'surprise': 0.01,\n",
       "   'neutral': 0.05}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = FER(mtcnn=True)\n",
    "img = cv2.imread(r\"C:\\Users\\harsh\\Desktop\\video_analytics\\data\\Frame1.jpg\")\n",
    "result = detector.detect_emotions(img)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[229, 242, 234],\n",
       "        [229, 242, 234],\n",
       "        [229, 242, 234],\n",
       "        ...,\n",
       "        [222, 229, 222],\n",
       "        [222, 229, 222],\n",
       "        [222, 229, 222]],\n",
       "\n",
       "       [[229, 242, 234],\n",
       "        [229, 242, 234],\n",
       "        [229, 242, 234],\n",
       "        ...,\n",
       "        [222, 229, 222],\n",
       "        [222, 229, 222],\n",
       "        [222, 229, 222]],\n",
       "\n",
       "       [[229, 242, 234],\n",
       "        [229, 242, 234],\n",
       "        [229, 242, 234],\n",
       "        ...,\n",
       "        [222, 229, 222],\n",
       "        [222, 229, 222],\n",
       "        [222, 229, 222]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[122, 156, 169],\n",
       "        [123, 157, 170],\n",
       "        [124, 156, 169],\n",
       "        ...,\n",
       "        [ 42,  58,  64],\n",
       "        [ 44,  61,  64],\n",
       "        [ 42,  61,  64]],\n",
       "\n",
       "       [[125, 157, 170],\n",
       "        [125, 157, 170],\n",
       "        [124, 156, 169],\n",
       "        ...,\n",
       "        [ 42,  58,  64],\n",
       "        [ 44,  61,  64],\n",
       "        [ 42,  61,  64]],\n",
       "\n",
       "       [[126, 158, 171],\n",
       "        [126, 158, 171],\n",
       "        [124, 156, 169],\n",
       "        ...,\n",
       "        [ 42,  58,  64],\n",
       "        [ 44,  61,  64],\n",
       "        [ 42,  61,  64]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_box = result[0][\"box\"]\n",
    "emotions = result[0][\"emotions\"]\n",
    "#Bounding around face is drawn\n",
    "cv2.rectangle(img,(bounding_box[0], bounding_box[1]),\n",
    "(bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3]),(0, 155, 255), 2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, (emotion, score) in enumerate(emotions.items()):\n",
    "    color = (211, 211, 211) if score < 0.01 else (255, 0, 0)\n",
    "    emotion_score = \"{}: {}\".format(\n",
    "          emotion, \"{:.2f}\".format(score) if score > 0.01 else \"\"\n",
    "        )\n",
    "    cv2.putText(img,emotion_score,\n",
    "            (bounding_box[0], bounding_box[1] + bounding_box[3] + 30 + idx * 15),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA,)\n",
    "cv2.imwrite(\"emotion.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the image \n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0) & 0xFF\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\external_software\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from fer import FER\n",
    "detector = FER(mtcnn=True)\n",
    "img = cv2.imread(r\"C:\\Users\\harsh\\Desktop\\video_analytics\\data\\Frame1.jpg\")\n",
    "result = detector.detect_emotions(img)\n",
    "bounding_box = result[0][\"box\"]\n",
    "emotions = result[0][\"emotions\"]\n",
    "#Bounding around face is drawn\n",
    "cv2.rectangle(img,(bounding_box[0], bounding_box[1]),\n",
    "(bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3]),(0, 155, 255), 2,)\n",
    "for idx, (emotion, score) in enumerate(emotions.items()):\n",
    "    color = (211, 211, 211) if score < 0.01 else (255, 0, 0)\n",
    "    emotion_score = \"{}: {}\".format(\n",
    "          emotion, \"{:.2f}\".format(score) if score > 0.01 else \"\"\n",
    "        )\n",
    "    cv2.putText(img,emotion_score,\n",
    "            (bounding_box[0], bounding_box[1] + bounding_box[3] + 30 + idx * 15),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1,cv2.LINE_AA,)\n",
    "cv2.imwrite(r\"C:\\\\Users\\\\harsh\\\\Desktop\\\\video_analytics\\\\images\\\\emotion.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
